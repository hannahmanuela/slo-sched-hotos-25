\section{Related Work}

Many other projects have explored how to do better serverless scheduling.
 
Systems like Sparrow\cite{TODO}, Hermod\cite{TODO}, or Kairos\cite{TODO} improve
performance of scheduling in the distributed setting by trying out and using
different scheduling policies. Unlike \sys{}, they do not differentiate betwen
individual types of jobs that come in.

% Other projects do just that: generate better scheduling decisions by getting
% access to more information about the workload. There are two different ways of
% going about this: learn the behaviors, or ask developers to specify. 

Some systems generate information about jobs that are coming in to help
placement decisions; for instance ALPS\cite{TODO}, which observes and learns the
behaviors of existing functions and then makes scheduling decisions based on
those; or Morpheus\cite{TODO}, which learns SLOs from historical runs, and then
translates these to recurring reservations.\ \sys{} instead gets the priorities
directly from the developers as part of its interface.


Other existing systems ask developers to specify the desired behavior, like
\sys{} does. However, they don't change the actual underlying machine-level
scheduling, and expressing priority is more complex than in \sys{} and/or
has a different goal.

Sequoia\cite{TODO}, for instance, adds a metric of QOS. Unlike \sys{}, Sequoia
does not implement a scheduler, but builds a prioritization in front of AWS
lambda. 

Another project\cite{TODO} creates a language of Allocation Priority Policies
(APP), which is a declarative language to express policies, then builds a
scheduler around that. Unlike \sys{}, the APP language is built around making
load balancing decisions and ultimately defines a mapping of jobs to workers,
rather than assocaiting priorities with the jobs and having the scheduler do the
scheduling automatically.

AWS lambda itself also goes this route, by offering two different ways for
developers to influence lambda function scaling: provisioned and reserved
concurrency. Provisioned concurrency specifies a number of instances to keep
warm, and reserved concurrency does the same but ensures that those warm
instances are kept for a specific function. However, these knobs are more
centered around mitigating the effects of cold start rather than actually
affecting the way the  jobs are scheduled.
