\section{Related Work}

Many other projects have explored how to do better scheduling for data centers.
 
Systems like Sparrow\cite{sparrow}, Hermod\cite{hermod}, or Kairos\cite{kairos}
improve performance of scheduling in the distributed setting by trying out and
using different scheduling policies. Unlike \sys{}, they treat all functions
equally.

Like \sys{}, many projects tailor their approach to serverless. Some systems
generate information about functions themselves to help placement decisions; for
instance ALPS\cite{alps}, which observes and learns the behaviors of existing
functions and then makes scheduling decisions based on those; or
Morpheus\cite{morpheus}, which learns SLOs from historical runs, and then
translates these to recurring reservations.~\Sys{} instead gets the \class{}es
directly from the developers as part of its interface.

Other papers have taken the same approach as \sys{} of getting information to
help scheduling from the developers. Sequoia\cite{sequoia}, for instance,
creates a metric of QOS for serverless functions. Unlike \sys{} however, Sequoia
does not implement a new scheduler, but is itself a serverless function that
manages the invocation sequence of developer's function chains by interposing on
the triggers and choosing what to invoke when. Therefore it also, unlike
\sys{}, does not support multi-tenancy.

Allocation Priority Policies (APP)\cite{app-paper} provides a declarative
language to express policies, then builds a scheduler around that. The APP
language is built around allowing developers to specify custom load balancing
decisions, and the scheduler uses the developers' specification to define a
mapping of function invocations to workers. \Sys{}, on the other hand, does not
ask developers to set the load balancing policy, but rather has developers give
\sys{} the information it needs to do the load balancing itself.

AWS offers two different ways for developers to influence their functions'
scaling: provisioned and reserved concurrency\cite{aws-scaling}. Provisioned
concurrency specifies a number of instances to keep warm for a given function,
and reserved concurrency ensures that a fixed amount of the possible concurrency
reserved for it. This interface is bad for serverless workloads for the same
reasons that reservation-based systems are: it requires developers to estimate
their future needs and pay up front, and providers to keep those potentially
idle resources available.

On the serverful side of scheduling, priorities are generally expressed via a
latency critical/best effort binary, where latency critical processes have an
attached amount of resource reservations, and best effort processes
don't~\cite{kubernetes-lc-be}. Serverless schedulers that sit on top of
Kubernetes, such as OpenFaaS~\cite{openfaas} or Knative~\cite{knative}, use
autoscaling to keep up with load, and use the same interface as kubernetes for
developers to express resource requirements~\cite{knative-res, openfaas-res}.
This works well for long running servers with steady amounts of load, since
predictable load will allow developers to make good approximations of the
resources they will need. The serverless setting \sys{} works within is
different because both the number of invocations and the resource usage of each
invocation is expected to vary. 
