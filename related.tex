\section{Related Work}

There is a large literature on scheduling for data centers but none
address the \problem.  Systems like Sparrow\cite{sparrow},
Hermod\cite{hermod}, or Kairos\cite{kairos} improve performance of
scheduling in the distributed setting by trying out and using
different scheduling policies. Unlike \sys{}, they treat all functions
equally.

Like \sys{}, many projects tailor their approach to serverless. Some systems
generate information about functions themselves to help placement decisions; for
instance ALPS\cite{alps}, which observes and learns the behaviors of existing
functions and then makes scheduling decisions based on those; or
Morpheus\cite{morpheus}, which learns SLOs from historical runs, and then
translates these to recurring reservations.~\Sys{} instead obtains the \class{}es
directly from the developers and bases its decisions solely on \class{}es.

Other papers have taken the same approach of obtaining information
from the developers. Sequoia~\cite{sequoia}, for instance, creates a
metric of QOS for serverless functions. Unlike \sys{} however, Sequoia
does not implement a new scheduler, but is itself a serverless
function that manages the invocation sequence of developer's function
chains by interposing on the triggers and choosing what to invoke
when. This design does not support multi-tenancy.

Allocation Priority Policies (APP)~\cite{app-paper} provides a
declarative language to express policies that allow a tenant to assign
a function to one of their pods. APP doesn't, however, support
scheduling competing functions from different tenants.

%% The APP
%% language allows developers to specify custom load balancing
%% decisions, and the scheduler uses the developers' specification to define a
%% mapping of function invocations to workers. \Sys{}, on the other hand, does not
%% ask developers to set the load balancing policy, but rather has developers give
%% \sys{} the information it needs to do the load balancing itself.

AWS offers two different ways for developers to influence their functions'
scaling: provisioned and reserved concurrency\cite{aws-scaling}. Provisioned
concurrency specifies a number of instances to keep warm for a given function,
and reserved concurrency ensures that a fixed amount of the possible concurrency
reserved for it. This interface is bad for serverless workloads for the same
reasons that reservation-based systems are: it requires developers to estimate
their future needs and pay up front, and providers to keep those potentially
idle resources available. It also does not solve the \problem{}: it only ensures
that a single tenants different functions don't crowd each other.

Serverless orchestration systems like Dirigent~\cite{dirigent} are orthogonal to
\sys{}: their approaches can be combined to further reduce the latency overheads
that functions face.

On the serverful side of scheduling, developers can express priorities
by marking tasks latency critical or best effort, where latency
critical tasks have an attached amount of resource reservations, and
best effort processes don't~\cite{kubernetes-lc-be}.  This approach
works well for long running servers with steady amounts of load, since
predictable load will allow developerss to make good approximations of
the resources they will need. The serverless setting \sys{} works
within is different because both the number of invocations and the
resource usage of each invocation is expected to vary.

\Sys{} takes a market-like approach to scheduling, but market-based
approaches typically run an auction and give resources to the highest
bidder~\cite{bellagio-market-based,online-auctioning}. \Sys{} avoids
bidding because of the developer-side uncertainty it creates. AWS spot
instance~\cite{spot-instance-pricing} support bidding, but AWS charges
only the market rate, which is adjusted
slowly~\cite{spot-instance-history}; bidding amounts to a cap of how
much tenants are willing to spend. \Sys{} similarly sets a market
rate, but always charges that amount, and targets a different time
scale as well as level of guarantee than spot instances.


