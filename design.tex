\section{Design}




Developers using \sys{} write function handlers and define triggers just like
they would for any existing serverless offering. Additionally, developers
express priorities to \sys{}, and \sys{} enforces these priorities.



\subsection{Interface}

Developers express priorities to \sys{} via assigning functions to fixed dollar
amounts per unit compute. So in the example of the web server, the home page
view might be assigned a high priority and cost 2c per cpu second, a the user
profile view might be a assigned a middle-high priority and cost 1.5c per cpu
second, and finally the map reduce job can be set to a low priority which costs
only 0.5c per cpu second.
 
To avoid unexpected costs in the case of for example a DOS attack or a bug,
developers also express a monthly budget that they are willing to pay.
\sys{} does not guarantee that the budget will not be exceeded by small amounts,
but can use it as a guideline and throttle invocations or decrease quality of
service in the case that usage is not within reason given the expected budget.

Finally, developers are required to express a maximum amount of memory per
function.\hmng{ Should I have a forward reference to the discussion section
here? }



\subsection{Internals}

\sys{} consists of a distributed global scheduler, which places new function
invocations, and a machine scheduler, which enforces priorities on the machines.


\textbf{Machine Scheduler.} 
The machine scheduler has a simple paradigm: processes have fixed priorities,
and higher priorities preempt lower priorities. Being unfair and starving low
priority processes is a feature, not a bug: map reduce jobs should not ever
interrupt a page view request processing.

On each machine is also running a dispatcher that is in charge of communicating
with global scheduler shards. The dispatcher is in charge of informing a gloabl
scheduler shard in the event that it has idle resources (ie if memory
utilization is low). Each shard has an attached `free list', the dispatcher
chooses which list to add itself to using a power-of-k-choices mechanism: it
looks at k shards and chooses the one with the least other machines in it. 

The dispatcher is also in charge of starting new jobs assigned to its machine,
as well as killing and then requeing jobs under memory pressure. It chooses the
job to kill by looking at both memory used and money wasted if killed (lower
priority jobs should be the ones to be killed if possible, but won't help much
if they weren't using any memory to begin with).



\textbf{Global Scheduler.}
The global scheduler is sharded, and each shard maintains a multi-queue of
functions assigned (one queue per priority), as well as the aforementioned `free
list'. 

Because machines only add themselves and their availability information to one
shard at a time, the information in the `free list' may be outdated, but it will
always be a pessimistic estimate of the current state of the machine.

\begin{algorithm}[t]
\caption{Chooses a machine for a job j}\label{alg:place}
\begin{algorithmic}
    \State$N = \{ $ machines in freeList with memAvail > j.maxMem $\}$
    \If{$|N| > 0$} \\
        \Return$ $min(N.maxPriorityRunning, N.qSize)
    \EndIf
    \State$M = $ timeToProfit of k polled machines
    \If{min(M.timeToProfit$) < THRESH$} \\
        \Return$ $min($M$)
    \Else
        \State$ $reQ j, with priority -= 1
    \EndIf
\end{algorithmic}
\end{algorithm}

Shards choose what job to place next by the ratio of priority to amount of
time spent in the queue, so high priority jobs don't have to wait as long
as lower priority jobs to be chosen next.

When placing a job, the shard finds a machine to run the it, as also shown in
the pseudocode in Algorithm \ref{alg:place}. \\
The shard will first look in its `free list' for a machine that has the job's
maximum memory available; if there are multiple such machines, the shard looks
at each machines highest currently running priority and number of jobs. The goal
is to minimize cpu idleness and job latency in low load settings.\hmng{playing
with how to relate these to each other and how to make this decision in the
scheduler right now} \\
If there are no machines in the `free list' with the memory available, the shard
switches over to power-of-k-choices: it polls k machines, sending the priority
and the maximum memory of the job currently being placed. The shard gets back a
number that represents the time it would take for the machine to start making a
profit off of the decision of placing the job there. This number is influenced
by what job the machine would kill, how long that has been running, and what the
price differential is between the new and the potentially killed job. This value
captures the sunk cost of killing a job, as well as the implicit opportunity
cost in that the lower priority job being killed would otherwise keep running.
\\ 
The shard then can choose to place the new job on the machine with the minimum
value, or if all of them are too high the shard re-queues the job, this time
with a lower priority.

Checking in with clients' budgets to ensure that usage is not significantly
outpacing a rate compatible with the budget is done asynchronously: each time a
job for a client is triggered a global counter is asynchronously updated. If the
counter's rate of change increases absurdly with regards to previous behavior as
well as the budget as a whole, this triggers a throttling for that job.
