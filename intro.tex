%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------

A world where all cloud compute is run in the format of serverless jobs is
attractive to developers and providers: developers pay only for what they use,
while having access to many resources when needed; and cloud providers have
control over scheduling and can use that to drive up utilization.


However, for many applications it is rare to see them entirely hosted on
serverless offerings today\cite{TODO}. Consider a web server: its
characteristics of unpredictable and bursty traffic make it well-suited for
serverless, and the pay as you go model is particularly attractive to website
developers who don't want to have to worry about provisioning.

Suppose a simple web server consists of two different page views, one for the
landing page and another for users' profile pages, and also has map reduce jobs
for data processing. It is important that the page views finish quickly, with
the landing page taking precedence over the profile pages, and the map reduce
jobs can be run in the background and be delayed.

If a web developer wanted to host their web in an existing serverless offering,
a popular option is AWS lambda\cite{TODO}. However, AWS offers no way to
distinguish between different lambdas in order to ensure that the page views run
quickly, while having the notion that map reduce jobs don't have to. A developer
using AWS lambda could implicitly prioritize page views by avoiding cold starts
for only them (using reserved and provisioned concurrency); or could give them
more concurrency (through `vCPUs'). However, neither of these give priority to
the page views when they run.\hmng{I feel like this is too vague to be a strong
and convincing thing to say}

This paper focuses on building a usable and efficient scheduling mechanism to
support differentiating between jobs of different priorities in a world of
universal serverless. In doing so, it faces multiple significant challenges.

One of the challenges is that of placing jobs quickly enough. This means that a
job that takes 20ms to run cannot spend 100ms in scheduler queues and waiting
for an execution environment before even starting to run. One part of this
challenge is cold starts, but for this paper, we assume that that generally cold
start times are small enough compared to the jobs being run that cold starts on
the critical path are acceptable.\footnote{Cold start latencies are a popular
area of research and as a result have been reduced significantly --- recent
state of the art systems have been able to support latencies in the single digit
ms range\cite{TODO}. We expect this trend to continue.} We focus on the aspect
of scheduling latency: in a datacenter, where both the number of new jobs coming
in and the amount of resources are extremely large, the challenge is knowing
where the free and idle resources are, or finding out quickly.

Another challenge is that of multi-tenancy. The fact that page views are more
important to a web server than map reduce jobs is a relative statement: there is
no way of mapping that prioritization to other peoples jobs, in order to be able
to directly compare which job should run when. And, in fact, developers cannot
be trusted to make such a comparison, their own jobs will always seem more
important than others': if given an absolute scale from 0-99 (0 being the
highest priority), the highest priority job will always get a 0 and the rest
will be relative to that. However, that does not reflect that in fact different
clients do have different requirements and expectations, and need to be treated
differently.

A third main challenge is that of managing memory. Given that machines are
limited in memory, placing a new high priority job invocation on a machine
already running many jobs may or may not lead to enough memory pressure to
require killing an already placed job (rather than just preempting other jobs).
It is difficult to know whether that would be the case, and if so whether it is
worth it, or better to just requeue the new job.

 
